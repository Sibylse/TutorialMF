---
title: "Literature"
layout: post
---
We  will summarize, compare and discuss in particular the following references:

## SVD and PCA

[**Baldi and Hornik 1989**] Baldi, Pierre and Kurt Hornik. “Neural networks and principal component analysis: Learning from examples without local minima.” _Neural Networks 2_ (1989).

[**Refinetti and Goldt 2022**] Refinetti, Maria and Sebastian Goldt. “The dynamics of representation learning in shallow, non-linear autoencoders.” _ArXiv abs/2201.02115_ (2022)

[**Tzeng et al. 2022**] Tzeng, R., Wang, P., Adriaens, F., Gionis, A., & Lu, C. (2022). Improved analysis of randomized SVD for top-eigenvector approximation. _ArXiv, abs/2202.07992_, accepted at AISTATS 22.

[**Baglama & Reichel 2005**] Baglama, J., & Reichel, L. (2005). Augmented implicitly restarted Lanczos bidiagonalization methods. _SIAM Journal on Scientific Computing_.

[**Bai et al. 2021**] Bai, X., Buccini, A., & Reichel, L. (2021). Golub–Kahan vs. Monte Carlo: a comparison of bidiagonlization and a randomized SVD method for the solution of linear discrete ill-posed problems. _BIT Numerical Mathematics_.

[**Cavazza et al. 2018**] Cavazza, J., Morerio, P., Haeffele, B.D., Lane, C., Murino, V., & Vidal, R. (2018). Dropout as a Low-Rank Regularizer for Matrix Factorization. _AISTATS_.

[**Fan 1949**] Fan, K. (1949). On a Theorem of Weyl Concerning Eigenvalues of Linear Transformations I. Proceedings of the National Academy of Sciences of the United States of America, 35 11, 652-5 .

## NMF

[**Aggarwal 2018**] Aggarwal, C.C. (2018). Matrix Factorization and Topic Modeling.

[**Bolte et al. 2014**] Bolte, J., Sabach, S., & Teboulle, M. (2014). Proximal alternating linearized minimization or nonconvex and nonsmooth problems. _Mathematical Programming_.

[**Copar et al. 2019**] Copar, A., Zupan, B., & Zitnik, M. (2019). Fast optimization of non-negative matrix tri-factorization. _PloS one_.

[**Driggs et al. 2020**] Driggs, D., Tang, J., Liang, J., Davies, M., & Schönlieb, C.B. (2020). Spring: A fast stochastic proximal alternating method for non-smooth non-convex optimization. _arXiv preprint arXiv:2002.12266_.

[**Gaussier & Goutte 2005**] Gaussier, É., & Goutte, C. (2005). Relation between PLSA and NMF and implications. SIGIR '05.

[**Gillis & Glineur 2012**] Gillis, N., & Glineur, F. (2012). Accelerated multiplicative updates and hierarchical ALS algorithms for nonnegative matrix factorization. _Neural computation_.

[**Grippo & Sciandrone 2000**] Grippo, L., & Sciandrone, M. (2000). On the convergence of the block nonlinear Gauss–Seidel method under convex constraints. _Operations research letters_.

[**Kim et al. 2014**] Kim, J., He, Y., & Park, H. (2014). Algorithms for nonnegative matrix and tensor factorizations: A unified view based on block coordinate descent framework. _Journal of Global Optimization_.

[**Le et al. 2020**] Le, H., Gillis, N., & Patrinos, P. (2020). Inertial block proximal methods for non-convex non-smooth optimization. _International Conference on Machine Learning_ (ICML).

[**Lee & Seung 1999**] Lee, D., & Seung, H. (1999). Learning the parts of objects by non-negative matrix factorization. _Nature_.

[**Lee & Seung 2001**] Lee, D., & Seung, H. (2001). Algorithms for non-negative matrix factorization. _Advances in neural information processing systems_ (NeurIPS).

[**Lin 2007**] Lin, C.J. (2007). Projected gradient methods for nonnegative matrix factorization. _Neural computation_.

[**Li & Ding 2006**] Li, T., & Ding, C. (2006). The relationships among various nonnegative matrix factorization methods for clustering. _International Conference on Data Mining_ (ICDM).

[**Mair & Brefeld 2019**] Mair, S., & Brefeld, U. (2019). Coresets for Archetypal Analysis. _NeurIPS_.

[**Parikh & Boyd 2014**] Parikh, N., & Boyd, S. (2014). Proximal algorithms. _Foundations and Trends in Optimization_.

[**Peharz et al. 2010**] Peharz, R., Stark, M., & Pernkopf, F. (2010). Sparse nonnegative matrix factorization using ℓ0-constraints. _IEEE International Workshop on Machine Learning for Signal Processing_.

[**Pock & Sabach 2016**] Pock, T., & Sabach, S. (2016). Inertial proximal alternating linearized minimization (iPALM) for nonconvex and nonsmooth problems. _SIAM Journal on Imaging Sciences_.

[**Sivaprasad et al. 2021**] Sivaprasad, S., Singh, A., Manwani, N., & Gandhi, V. (2021). The Curious Case of Convex Neural Networks. _ECML/PKDD_.

[**Wang & Zhang 2013**] Wang, Y.X., & Zhang, Y.J. (2013). Nonnegative matrix factorization: A comprehensive review. _IEEE Transactions on Knowledge and Data Engineering_ (TKDE).

## k-means

[**Bauckhage 2015**] Bauckhage, C. (2015). K-means clustering is matrix factorization. _arXiv preprint arXiv:1512.07548_.

[**Fernsel 2021**] Fernsel, P. (2021). Spatially Coherent Clustering Based on Orthogonal Nonnegative Matrix Factorization. _Journal of Imaging_.

[**Lloyd 1982**] Lloyd, S. (1982). Least squares quantization in PCM. _IEEE transactions on information theory_.

[**Pompili et al. 2014**] Pompili, F., Gillis, N., Absil, P.A., & Glineur, F. (2014). Two algorithms for orthogonal nonnegative matrix factorization with application to clustering. _Neurocomputing_.

[**Whang et al. 2015**] Whang, J., Dhillon, I., & Gleich, D. (2015). Non-exhaustive, overlapping k-means. _Proceedings of the SIAM International Conference on Data Mining_ (SDM).

[**Zha et al. 2002**] Zha, H., He, X., Ding, C., Gu, M., & Simon, H. (2002). Spectral relaxation for k-means clustering. _Advances in neural information processing systems_ (NeurIPS).

## Nonconvex Clustering

[**Dhillon et al. 2004**] Dhillon, I., Guan, Y., & Kulis, B. (2004). Kernel k-means: spectral clustering and normalized cuts. _Proceedings of the ACM SIGKDD international conference on Knowledge discovery and data mining_ (SIGKDD).

[**Ding et al. 2005**] Ding, C., He, X., & Simon, H. (2005). On the equivalence of nonnegative matrix factorization and spectral clustering. _Proceedings of the SIAM International Conference on Data Mining_ (SDM).

[**Ding et al. 2008**] Ding, C., Li, T., & Jordan, M. (2008). Nonnegative matrix factorization for combinatorial optimization: Spectral clustering, graph matching, and clique finding. _IEEE International Conference on Data Mining_ (ICDM).

[**Hess et al. 2019**] Hess, S., Duivesteijn, W., Honysz, P., & Morik, K. (2019). The SpectACl of Nonconvex Clustering: A Spectral Approach to Density-Based Clustering. _Proceedings of the AAAI Conference on Artificial Intelligence_ (AAAI).

[**Schölkopf et al. 1998]** Schölkopf, B., Smola, A., & Müller, K.R. (1998). Nonlinear component analysis as a kernel eigenvalue problem. _Neural computation_.

[**Von Luxburg 2007**] Von Luxburg, U. (2007). A tutorial on spectral clustering. _Statistics and computing_.

## Biclustering

[**Del Buono & Pio 2015**] Del Buono, N., & Pio, G. (2015). Non-negative matrix tri-factorization for co-clustering: an analysis of the block matrix. _Information Sciences_.

[**Dhillon 2001**] Dhillon, I. (2001). Co-clustering documents and words using bipartite spectral graph partitioning. _Proceedings of the ACM SIGKDD international conference on Knowledge discovery and data mining_ (SIGKDD).

[**Ding et al. 2006**] Ding, C., Li, T., Peng, W., & Park, H. (2006). Orthogonal nonnegative matrix t-factorizations for clustering. _Proceedings of the ACM SIGKDD international conference on Knowledge discovery and data mining_ (SIGKDD).

[**Fischer & Vreeken 2021**] Fischer, J., & Vreeken, J. (2021). Differentiable Pattern Set Mining. Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining.

[**Han et al. 2017**] Han, J., Song, K., Nie, F., & Li, X. (2017). Bilateral k-means algorithm for fast co-clustering. _Proceedings of the AAAI Conference on Artificial Intelligence_ (AAAI).

[**Henriques et al. 2015**] Henriques, R., Antunes, C., & Madeira, S. (2015). A structured view on pattern mining-based biclustering. _Pattern Recognition_.

[**Hess et al. 2017**] Hess, S., Morik, K., & Piatkowski, N. (2017). The PRIMPING routine: tiling through proximal alternating linearized minimization. _Data Mining and Knowledge Discovery_.

[**Hess et al. 2018**] Hess, S., Piatkowski, N., & Morik, K. (2018). The Trustworthy Pal: controlling the False Discovery Rate in Boolean Matrix Factorization. _Proceedings of the SIAM International Conference on Data Mining_ (SDM).

[**Hess et al. 2021**] Hess, S., Pio, G., Hochstenbach, M.E., & Ceci, M. (2021). BROCCOLI: overlapping and outlier-robust biclustering through proximal stochastic gradient descent. Data Min. Knowl. Discov., 35, 2542-2576.

[**Kriegel et al. 2009**] Kriegel, H.P., Kröger, P., & Zimek, A. (2009). Clustering high-dimensional data: A survey on subspace clustering, pattern-based clustering, and correlation clustering. _ACM Transactions on Knowledge Discovery from Data_ (TKDD).

[**Madeira & Oliveira 2004**] Madeira, S., & Oliveira, A. (2004). Biclustering algorithms for biological data analysis: a survey. _IEEE/ACM Transactions on Computational Biology and Bioinformatics_ (TCBB).

[**Miettinen et al. 2008**] Miettinen, P., Mielikäinen, T., Gionis, A., Das, G., & Mannila, H. (2008). The discrete basis problem. _IEEE Transactions on Knowledge and Data Engineering_ (TKDE).

[**Miettinen & Neumann 2020**] Miettinen, P., & Neumann, S. (2020). Recent Developments in Boolean Matrix Factorization. _IJCAI_.

[**Nie et al. 2017**] Nie, F., Wang, X., Deng, C., & Huang, H. (2017). Learning a structured optimal bipartite graph for co-clustering. _Advances in Neural Information Processing Systems_ (NeurIPS).

[**Song et al. 2021**] Song, K., Yao, X., Nie, F., Li, X., & Xu, M. (2021). Weighted bilateral K-means algorithm for fast co-clustering and fast spectral clustering. _Pattern Recognition_.

[**Wang et al. 2011**]Wang, H., Nie, F., Huang, H., & Makedon, F. (2011). Fast nonnegative matrix tri-factorization for large-scale data co-clustering. _IJCAI Proceedings-International Joint Conference on Artificial Intelligence_ (IJCAI).

[**Zha et al. 2001**] Zha, H., He, X., Ding, C., Simon, H., & Gu, M. (2001). Bipartite graph partitioning and data clustering. _Proceedings of the international conference on Information and knowledge management_.

[**Zhang et al. 2010**] Zhang, Z.Y., Li, T., Ding, C., Ren, X.W., & Zhang, X.S. (2010). Binary matrix factorization for analyzing gene expression data. _Data Mining and Knowledge Discovery_.

## Deep Learning as Kernel k-means

[**Hess et al. 2020**] Hess, S., Duivesteijn, W., & Mocanu, D.C. (2020). Softmax-based Classification is k-means Clustering: Formal Proof, Consequences for Adversarial Attacks, and Improvement through Centroid Based Tailoring. _ArXiv, abs/2001.01987_.

[**Niepert et al. 2021**] Niepert, M., Minervini, P., & Franceschi, L. (2021). Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions. ArXiv, abs/2106.01798.

[**Sinhamahapatra et al. 2022**] Sinhamahapatra, P., Koner, R., Roscher, K., & Günnemann, S. (2022). Is it all a cluster game? - Exploring Out-of-Distribution Detection based on Clustering in the Embedding Space. _ArXiv, abs/2203.08549_.
